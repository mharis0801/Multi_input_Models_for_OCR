# Multi_input_Models_for_OCR

# OCR Insurance ID Classifier

**Project senario:**

DigiNsure Inc. is digitizing historical insurance claim documents to improve the efficiency of claims processing and customer service. This project implements a multi-modal deep learning pipeline that uses both **scanned ID images** and **insurance type metadata** to classify insurance IDs as either **primary** or **secondary**.

---

## Project Overview

- **Goal:**  
  Automate the labeling of scanned insurance claim IDs as *primary* or *secondary* using both image and metadata.
- **Approach:**  
  - Multi-modal neural network with two branches:
    - Visual features from scanned ID images
    - Structured metadata (insurance type: home, life, auto, health, other)
  - Synthetic dataset generation for prototyping and evaluation

---

## Dataset

- **Source:**  
  Synthetic dataset generated by `ProjectDataset` (see [`project_utils.py`]).
- **Features:**
  - **Image:** 64x64 grayscale image of a random alphanumeric code
  - **Insurance Type:** One-hot vector for one of five types (`home`, `life`, `auto`, `health`, `other`)
  - **Label:** Binary (`primary_id` or `secondary_id`)

**Sample Visualization:**  
![digitizing_team](digitizing_team.png)

---

## Model Architecture

The classifier (`OCRModel`) is a simple multi-modal neural network with two parallel branches:

| Branch         | Details                                           |
| -------------- | ------------------------------------------------- |
| **Image**      | Conv2d → MaxPool → ReLU → Flatten → Linear (128)  |
| **Type**       | Linear (5→10) → ReLU                              |
| **Fusion**     | Concatenate image and type features → Linear (2)   |

**Forward Pass:**
```
def forward(self, x_image, x_type):
x_image = self.image_layer(x_image)
x_type = self.type_layer(x_type)
x = torch.cat((x_image, x_type), dim=1)
return self.classifier(x)
```


---

## Training Pipeline

- **Loss:** CrossEntropyLoss (binary classification)
- **Optimizer:** Adam
- **Batch Size:** 32
- **Epochs:** 10 (default)
- **Data Loading:**  
  Uses PyTorch `DataLoader` for batching and shuffling.

**Sample Training Loop:**
```
for epoch in range(10):
model.train()
running_loss = 0.0
for (images, types), labels in train_loader:
optimizer.zero_grad()
outputs = model(images, types)
loss = criterion(outputs, labels)
loss.backward()
optimizer.step()
running_loss += loss.item()
print(f"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}")

```

---

## Getting Started

### Requirements

- Python 3.7+
- PyTorch
- torchvision
- Pillow (PIL)

### Installation
```
pip install torch torchvision pillow
```

### Running the Project

1. **Clone the repository** and ensure `notebook.ipynb` and `project_utils.py` are present.
2. **Open `notebook.ipynb`** in Jupyter or VSCode.
3. **Run all cells** to:
    - Generate and visualize the dataset
    - Train the multi-modal OCR classifier

---

## Key Files

| File              | Purpose                                        |
| ----------------- | ---------------------------------------------- |
| `notebook.ipynb`  | Main notebook: data generation, training, demo |
| `project_utils.py`| Dataset class and data utilities               |

---

## Results

- The loss decreases over epochs, indicating the model learns to distinguish primary and secondary IDs using both image and insurance type features.
- The architecture is modular and can be extended to real scanned document data with minimal changes.

---

